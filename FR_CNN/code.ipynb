{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    }
   ],
   "source": [
    "image_path = []\n",
    "name=\"path\\\\to\\\\folder\"\n",
    "for file_name in os.listdir(name):\n",
    "    image_path.append(os.path.join(name, file_name))\n",
    "\n",
    "imageDataFin = []\n",
    "imageLabels = []\n",
    "    \n",
    "# read face images and class labels\n",
    "for img in image_path:\n",
    "    imgRead = io.imread(img, as_grey=True)\n",
    "    imgRead = cv2.resize(imgRead, (250, 250)) \n",
    "    imageDataFin.append (imgRead)\n",
    "    labelRead = int(os.path.split(img)[1].split(\"_\")[0])\n",
    "#     print(labelRead)\n",
    "    imageLabels.append(labelRead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (308, 250, 250, 1)\n",
      "308 train samples\n",
      "77 test samples\n"
     ]
    }
   ],
   "source": [
    "# split the data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(imageDataFin), np.array(imageLabels), train_size=0.8, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "# fix the random seed for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "# configuration\n",
    "batch_size = 32\n",
    "# nb_classes = 38\n",
    "nb_classes =35\n",
    "nb_epoch = 15\n",
    "# image dimensions\n",
    "img_rows, img_cols = 250, 250\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# resdhape the data matrix\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# scale the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# one-hot encoding for the class label\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(250, 250,..., padding=\"valid\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 248, 248, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 246, 246, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 246, 246, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 484128)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               61968512  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                4515      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 35)                0         \n",
      "=================================================================\n",
      "Total params: 61,982,595\n",
      "Trainable params: 61,982,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/15\n",
      "308/308 [==============================] - 117s 379ms/step - loss: 8.5734 - acc: 0.0325 - val_loss: 3.5429 - val_acc: 0.0519\n",
      "Epoch 2/15\n",
      "308/308 [==============================] - 63s 203ms/step - loss: 3.4758 - acc: 0.0779 - val_loss: 3.4146 - val_acc: 0.0779\n",
      "Epoch 3/15\n",
      "308/308 [==============================] - 75s 245ms/step - loss: 2.9857 - acc: 0.2305 - val_loss: 2.8936 - val_acc: 0.3117\n",
      "Epoch 4/15\n",
      "308/308 [==============================] - 64s 207ms/step - loss: 2.0701 - acc: 0.4838 - val_loss: 1.9938 - val_acc: 0.5844\n",
      "Epoch 5/15\n",
      "308/308 [==============================] - 63s 205ms/step - loss: 1.1109 - acc: 0.7273 - val_loss: 1.4917 - val_acc: 0.6364\n",
      "Epoch 6/15\n",
      "308/308 [==============================] - 64s 207ms/step - loss: 0.6063 - acc: 0.8734 - val_loss: 1.1349 - val_acc: 0.7143\n",
      "Epoch 7/15\n",
      "288/308 [===========================>..] - ETA: 3s - loss: 0.3522 - acc: 0.9062"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "import os\n",
    "from keras.utils import plot_model\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/HP/Anaconda3/envs/tf/Lib/site-packages/graphviz-2.38/release/bin'\n",
    "\n",
    "# define the convolutional neural network model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# inputs = Input((250,250))\n",
    "# model = Model(inputs, model)\n",
    "print(model.summary())\n",
    "plot_model(model, to_file = 'C:/Users/HP/Desktop/model/model.png')\n",
    "\n",
    "\n",
    "# compile the CNN model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the CNN model\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaluation\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:', score[1])\n",
    "\n",
    "# find out which images are classified wrongly\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "correct_classified_indices = np.nonzero(predicted_classes == Y_test)[0]\n",
    "incorrect_classified_indices = np.nonzero(predicted_classes != Y_test)[0]\n",
    "if not incorrect_classified_indices:\n",
    "    print('\\nAll test samples are correctly recognized.')\n",
    "else:\n",
    "    print('The incorrect indices are:', incorrect_classified_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
