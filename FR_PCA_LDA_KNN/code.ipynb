{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required library\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n"
     ]
    }
   ],
   "source": [
    "#initializing global parameters\n",
    "folder_tr = \"SEASFR/train\"\n",
    "folder_te = \"SEASFR/test\"\n",
    "total_tr = len(next(os.walk(os.getcwd()+\"/\"+folder_tr))[2])\n",
    "total_te = len(next(os.walk(os.getcwd()+\"/\"+folder_te))[2])\n",
    "dim = 72\n",
    "threshold = 90\n",
    "print(total_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance (LT)(L) (1056, 1056)\n",
      "(1056, 22)\n"
     ]
    }
   ],
   "source": [
    "#PCA algorithm\n",
    "#preparing lookup array\n",
    "lookup = []\n",
    "def fn(text):\n",
    "    ans=[]\n",
    "    for x in text:\n",
    "        if x == '_':\n",
    "            return (ans)\n",
    "        elif x== 'O':\n",
    "            return (ans)\n",
    "        elif x == 'o':\n",
    "            return (ans)\n",
    "        else:\n",
    "            ans+=x\n",
    "\n",
    "for filename in os.listdir(os.getcwd()+\"/\"+folder_tr):\n",
    "    ans = fn(filename)\n",
    "    ans = ''.join(str(e) for e in ans)\n",
    "    lookup.append(ans)\n",
    "\n",
    "#L is set of all training images\n",
    "#Currently L is zero matrix\n",
    "\n",
    "L = np.empty(shape=(dim*dim,total_tr), dtype='float64')\n",
    "i = 0\n",
    "for filename in os.listdir(os.getcwd()+\"/\"+folder_tr):\n",
    "    #Read a image \n",
    "    image = cv2.imread(folder_tr+\"/\"+filename)\n",
    "    resized = cv2.resize(image, (dim,dim), interpolation = cv2.INTER_AREA)\n",
    "    #Convert it into grayscale image\n",
    "    gray_image = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    #flattening an image\n",
    "    gray_vector = np.array(gray_image, dtype='float64').flatten()\n",
    "    L[:, i] = gray_vector[:] \n",
    "    i = i + 1\n",
    "\n",
    "#Mean face\n",
    "mean_face = np.sum(L, axis=1) /total_tr\n",
    "\n",
    "#subtract mean face\n",
    "for i in range(total_tr):\n",
    "    L[:,i] -= mean_face[:]\n",
    "\n",
    "LT = L.transpose()\n",
    "\n",
    "#calculate LTL: It is covariance matrix\n",
    "C = np.matmul(LT,L)  \n",
    "C = C/total_tr\n",
    "print(\"Covariance (LT)(L)\",C.shape)\n",
    "\n",
    "#calculate eigenvector and eigenvalue of covariance matrix\n",
    "evalues,evectors = np.linalg.eig(C)\n",
    "\n",
    "#getting correct ordering\n",
    "sort_indices = evalues.real.argsort()[::-1]\n",
    "evalues = evalues.real[sort_indices]\n",
    "evectors = evectors[sort_indices]\n",
    "\n",
    "#Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(evalues[i], evectors[:,i]) for i in range(len(evalues))]\n",
    "\n",
    "#decide value of K \n",
    "tot = sum(evalues)\n",
    "var_exp = [(i / tot)*100 for i in sorted(evalues, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "K = 0\n",
    "for i in range(len(cum_var_exp)):\n",
    "    K = i\n",
    "    if(int(cum_var_exp[i])>=threshold):\n",
    "        break\n",
    "\n",
    "\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,total_tr)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,total_tr)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Explained variance by different principal components')\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig)\n",
    "\n",
    "#taking K eigenvector and putting into cols of P\n",
    "P = np.reshape(eig_pairs[0][1],(C.shape[0],1))\n",
    "for j in range(K-1):\n",
    "    b = np.reshape(eig_pairs[j+1][1],(C.shape[0],1))\n",
    "    P = np.hstack((P,b))\n",
    "print(P.shape)\n",
    "    \n",
    "#projecting\n",
    "evectors = np.matmul(L,P)\n",
    "\n",
    "#normalize eigenvectors\n",
    "norms = np.linalg.norm(evectors, axis=0)\n",
    "evectors = evectors / norms \n",
    "#computing weights\n",
    "W = np.matmul(evectors.transpose(),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1056)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmm\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning:\n",
      "\n",
      "The priors do not sum to 1. Renormalizing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LDA starts..\n",
    "LDA_data = pd.DataFrame(W.transpose())\n",
    "LDA_data['label'] = lookup\n",
    "\n",
    "## This is our labeled data for LDA\n",
    "X = np.array(LDA_data.iloc[:,0:K])\n",
    "y = np.array(LDA_data.iloc[:,[K]])\n",
    "ltt = np.unique(y)\n",
    "y = np.reshape(y,(y.shape[0],))\n",
    "\n",
    "#### number of components taken in LDA\n",
    "l = len(ltt)-2\n",
    "\n",
    "#Apply LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "sklearn_lda = LinearDiscriminantAnalysis(n_components = l)\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### PCA_LDA classification\n",
    "#classification\n",
    "test_no = []\n",
    "i = 0\n",
    "wrong = 0\n",
    "for filename in os.listdir(os.getcwd()+\"/\"+folder_te):\n",
    "    ans = fn(filename)\n",
    "    #print(filename)\n",
    "    ans = ''.join(str(e) for e in ans)\n",
    "    test_no.append(ans)\n",
    "    test = cv2.imread(folder_te+\"/\"+filename)    # read as a grayscale image\n",
    "    test = cv2.resize(test, (dim,dim), interpolation = cv2.INTER_AREA)\n",
    "    test= cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)\n",
    "    img_col = np.array(test, dtype='float64').flatten()  \n",
    "    img_col -= mean_face                                           # subract the mean column\n",
    "    img_col = np.reshape(img_col, (dim*dim, 1))                             # from row vector to col vector\n",
    "\n",
    "    S = np.matmul(evectors.transpose(),img_col)                                # projecting the normalized probe onto the\n",
    "                                                                            # Eigenspace, to find out the weight\n",
    "    S = np.reshape(S, (1,S.shape[0]))\n",
    "    Xn = S \n",
    "    X_lda_res = sklearn_lda.transform(Xn)\n",
    "#     diff = means - X_lda_res                                    # finding the min ||W_j - S||\n",
    "    \n",
    "    if l>K:\n",
    "        X_lda_res = np.reshape(X_lda_res, (K,1))\n",
    "        X_lda_res = X_lda_res.T\n",
    "    else:\n",
    "        X_lda_res = np.reshape(X_lda_res, (l,1))\n",
    "        X_lda_res = X_lda_res.T\n",
    "    \n",
    "\n",
    "    norm = np.linalg.norm( X_lda_sklearn - X_lda_res,axis = 1)\n",
    "\n",
    "    point = []\n",
    "    point.append(np.array(norm).argsort())\n",
    "    #print(len(point))\n",
    "    #print(point)\n",
    "    #print(dic)    \n",
    "    recg = [(point[0][i],lookup[point[0][i]]) for i in range(len(point[0]))]\n",
    "    #print(recg)\n",
    "    \n",
    "    knn = []\n",
    "    for i in range(int(math.sqrt(len(point[0])))):\n",
    "        knn.append(recg[i][1])\n",
    "    \n",
    "    knn_unique = np.unique(knn)\n",
    "    knn_classify = []\n",
    "    for i in range(len(knn_unique)):\n",
    "        knn_classify.append(knn.count(knn_unique[i]))\n",
    "    classified = knn_unique[np.argmax(knn_classify)]\n",
    "    \n",
    "    if ans!= classified:\n",
    "        wrong = wrong + 1\n",
    "    #print(wrong)\n",
    "\n",
    "#Accuracy\n",
    "1 - wrong/total_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
